{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP/ld8sC9NVqlWRIbPVAtud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/diffusion/gligenzenn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation for gligen"
      ],
      "metadata": {
        "id": "1iNKMikD7qEl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXBZtybR7VjJ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate scipy safetensors\n",
        "!git clone https://github.com/gligen/diffusers.git\n",
        "!pip install git+https://github.com/gligen/diffusers.git\n",
        "# Installation for GroundingDINO\n",
        "%cd /content\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "%cd /content/GroundingDINO\n",
        "!pip install -q -e .\n",
        "!pip install -q roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "LxIiUJ-n8tD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from functools import partial\n",
        "import cv2\n",
        "import requests\n",
        "\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import torch\n",
        "from torchvision.ops import box_convert\n",
        "\n",
        "from groundingdino.models import build_model\n",
        "from groundingdino.util.slconfig import SLConfig\n",
        "from groundingdino.util.utils import clean_state_dict\n",
        "from groundingdino.util.inference import annotate, load_image, predict\n",
        "import groundingdino.datasets.transforms as T\n",
        "\n",
        "from huggingface_hub import hf_hub_download"
      ],
      "metadata": {
        "id": "00vSqrp68uM3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utils function"
      ],
      "metadata": {
        "id": "IH9kk6Zi8xzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_hf(repo_id, filename, ckpt_config_filename, device='cpu'):\n",
        "    cache_config_file = hf_hub_download(repo_id=repo_id, filename=ckpt_config_filename)\n",
        "\n",
        "    args = SLConfig.fromfile(cache_config_file) \n",
        "    model = build_model(args)\n",
        "    args.device = device\n",
        "\n",
        "    cache_file = hf_hub_download(repo_id=repo_id, filename=filename)\n",
        "    checkpoint = torch.load(cache_file, map_location='cpu')\n",
        "    log = model.load_state_dict(clean_state_dict(checkpoint['model']), strict=False)\n",
        "    print(\"Model loaded from {} \\n => {}\".format(cache_file, log))\n",
        "    _ = model.eval()\n",
        "    return model  "
      ],
      "metadata": {
        "id": "_uCgtS0d8yvG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load detection model and gligen model"
      ],
      "metadata": {
        "id": "xv19S-Uq9CxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load detection model\n",
        "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
        "ckpt_filenmae = \"groundingdino_swint_ogc.pth\"\n",
        "ckpt_config_filename = \"GroundingDINO_SwinT_OGC.cfg.py\"\n",
        "dino_model = load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename)"
      ],
      "metadata": {
        "id": "f0HMwvcK9FTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load gligen pipeline\n",
        "from diffusers import StableDiffusionGLIGENPipeline\n",
        "\n",
        "pipe = StableDiffusionGLIGENPipeline.from_pretrained(\"gligen/diffusers-inpainting-text-box\", revision=\"fp16\", torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "JM03QAoj9VXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference\n"
      ],
      "metadata": {
        "id": "4sh7zMFd8GFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download data for inference\n",
        "%cd /content\n",
        "!wget https://huggingface.co/ShilongLiu/GroundingDINO/resolve/main/art_dog_birthdaycake.png"
      ],
      "metadata": {
        "id": "ESaa__Jx8qX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grounding dino detection\n",
        "import os\n",
        "import supervision as sv\n",
        "\n",
        "local_image_path = \"art_dog_birthdaycake.png\"\n",
        "\n",
        "TEXT_PROMPT = \"dog. cake.\"\n",
        "BOX_TRESHOLD = 0.35\n",
        "TEXT_TRESHOLD = 0.25\n",
        "\n",
        "image_source, image = load_image(local_image_path)\n",
        "\n",
        "boxes, logits, phrases = predict(\n",
        "    model=dino_model, \n",
        "    image=image, \n",
        "    caption=TEXT_PROMPT, \n",
        "    box_threshold=BOX_TRESHOLD, \n",
        "    text_threshold=TEXT_TRESHOLD\n",
        ")\n",
        "\n",
        "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "annotated_frame = annotated_frame[...,::-1] # BGR to RGB"
      ],
      "metadata": {
        "id": "XRVKqH0K9wFh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display mask\n",
        "def generate_masks_with_grounding(image_source, boxes):\n",
        "    h, w, _ = image_source.shape\n",
        "    boxes_unnorm = boxes * torch.Tensor([w, h, w, h])\n",
        "    boxes_xyxy = box_convert(boxes=boxes_unnorm, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").numpy()\n",
        "    mask = np.zeros_like(image_source)\n",
        "    for box in boxes_xyxy:\n",
        "        x0, y0, x1, y1 = box\n",
        "        mask[int(y0):int(y1), int(x0):int(x1), :] = 255\n",
        "    return mask"
      ],
      "metadata": {
        "id": "PiE5sCqB912r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_mask = generate_masks_with_grounding(image_source, boxes)\n",
        "Image.fromarray(annotated_frame)"
      ],
      "metadata": {
        "id": "uSRwaUED97BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title gligen image inpainting\n",
        "image_source = Image.fromarray(image_source)\n",
        "annotated_frame = Image.fromarray(annotated_frame)\n",
        "image_mask = Image.fromarray(image_mask)\n",
        "# Resize\n",
        "image_source_for_inpaint = image_source.resize((512, 512))\n",
        "image_mask_for_inpaint = image_mask.resize((512, 512))\n",
        "# get bbox\n",
        "xyxy_boxes = box_convert(boxes=boxes, in_fmt=\"cxcywh\", out_fmt=\"xyxy\").tolist()\n",
        "\n",
        "# define prompts for each box\n",
        "gligen_phrases = ['a cat', 'a rose']\n",
        "prompt = \"'a cat', 'a rose'\"\n",
        "\n",
        "num_box = len(boxes)\n",
        "\n",
        "image_inpainting = pipe(\n",
        "    prompt,\n",
        "    num_images_per_prompt = 2,\n",
        "    gligen_phrases = gligen_phrases,\n",
        "    gligen_inpaint_image = image_source_for_inpaint,\n",
        "    gligen_boxes = xyxy_boxes,\n",
        "    gligen_scheduled_sampling_beta=1,\n",
        "    output_type=\"numpy\",\n",
        "    num_inference_steps=50\n",
        ").images"
      ],
      "metadata": {
        "id": "tXct-9WC-QR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display image\n",
        "image_inpainting = (image_inpainting * 255).astype(np.uint8)\n",
        "image_inpainting = np.concatenate(image_inpainting, axis=1)\n",
        "Image.fromarray(image_inpainting).resize((image_source.size[0]*2, image_source.size[1]))"
      ],
      "metadata": {
        "id": "7t6E2SFh-iNy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}