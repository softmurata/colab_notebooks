{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPf/BJeEMKO5seqZ1OFVx1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "028fba2d819b4d7b809012c806592567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_883b152d39884741b02385b2b76f4183",
              "IPY_MODEL_8394c08c71004d48a425076b55099193",
              "IPY_MODEL_b281f21ac150478e92b88481129339d5"
            ],
            "layout": "IPY_MODEL_e9c384fd1315473e8ccb1f92a4f0092e"
          }
        },
        "883b152d39884741b02385b2b76f4183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c927cc3dafd74518ba09d6a55bd3e9d1",
            "placeholder": "​",
            "style": "IPY_MODEL_a383d595fd6f41559c97c63cb3f4fb77",
            "value": "Fetching 15 files: 100%"
          }
        },
        "8394c08c71004d48a425076b55099193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70eb0b722b4245cd87fc3d951411c399",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b901f37d1aa84c9987cc1d51659948c1",
            "value": 15
          }
        },
        "b281f21ac150478e92b88481129339d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd12163f7d7645dabe22cc81ff59cb42",
            "placeholder": "​",
            "style": "IPY_MODEL_724619ed992148449286d06a666ddb3d",
            "value": " 15/15 [00:00&lt;00:00, 240.55it/s]"
          }
        },
        "e9c384fd1315473e8ccb1f92a4f0092e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c927cc3dafd74518ba09d6a55bd3e9d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a383d595fd6f41559c97c63cb3f4fb77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70eb0b722b4245cd87fc3d951411c399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b901f37d1aa84c9987cc1d51659948c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd12163f7d7645dabe22cc81ff59cb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "724619ed992148449286d06a666ddb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/app/gradioapp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY4uFyQJSSDy"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "HzPabAZ8TNt0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hello wolrd examples"
      ],
      "metadata": {
        "id": "-sKbqOboTs1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "LXKFbLb_SlhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Name Here Test...\"),\n",
        "    outputs=\"text\",\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "e91xdA05S6dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name, is_morning, temperature):\n",
        "    salutation = \"Good morning\" if is_morning else \"Good evening\"\n",
        "    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n",
        "    celsius = (temperature - 32) * 5 / 9\n",
        "    return greeting, round(celsius, 2)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n",
        "    outputs=[\"text\", \"number\"],\n",
        ")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "YcdpibZITX3z",
        "outputId": "1d311c2b-5317-4868-9003-9914bbeab551"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Image examples\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "\n",
        "def sepia(input_img):\n",
        "    sepia_filter = np.array([\n",
        "        [0.393, 0.769, 0.189], \n",
        "        [0.349, 0.686, 0.168], \n",
        "        [0.272, 0.534, 0.131]\n",
        "    ])\n",
        "    sepia_img = input_img.dot(sepia_filter.T)\n",
        "    sepia_img /= sepia_img.max()\n",
        "    return sepia_img\n",
        "\n",
        "demo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "6u6hEfowTvZX",
        "outputId": "d1aa4f0c-5637-4460-8426-80333793db31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7861, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title chatbot app"
      ],
      "metadata": {
        "id": "jh2RsD5iUJWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#style.css\n",
        "# create style.css\n",
        "\"\"\"\n",
        "col-container {max-width: 700px; margin-left: auto; margin-right: auto;}\n",
        "\n",
        "a {text-decoration-line: underline; font-weight: 600;}\n",
        ".footer {\n",
        "        margin-bottom: 45px;\n",
        "        margin-top: 10px;\n",
        "        text-align: center;\n",
        "        border-bottom: 1px solid #e5e5e5;\n",
        "    }\n",
        "    .footer>p {\n",
        "        font-size: .8rem;\n",
        "        display: inline-block;\n",
        "        padding: 0 10px;\n",
        "        transform: translateY(10px);\n",
        "        background: white;\n",
        "    }\n",
        "    .dark .footer {\n",
        "        border-color: #303030;\n",
        "    }\n",
        "    .dark .footer>p {\n",
        "        background: #0b0f19;\n",
        "    }\n",
        ".animate-spin {\n",
        "    animation: spin 1s linear infinite;\n",
        "}\n",
        "@keyframes spin {\n",
        "    from {\n",
        "        transform: rotate(0deg);\n",
        "    }\n",
        "    to {\n",
        "        transform: rotate(360deg);\n",
        "    }\n",
        "}\n",
        "#upload_button {\n",
        "  background-color: black;\n",
        "  color: white;\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "D1l_euyYUp4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install -qq git+https://github.com/huggingface/diffusers.git"
      ],
      "metadata": {
        "id": "9uR9ALUwULut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "nGiteSq6V6LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xformers triton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3SDX1gqWc9m",
        "outputId": "c0d3e947-bbd2-4ac3-9a3c-288a8d26040b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.8/dist-packages (0.0.16)\n",
            "Collecting triton\n",
            "  Downloading triton-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from xformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: pyre-extensions==0.0.23 in /usr/local/lib/python3.8/dist-packages (from xformers) (0.0.23)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xformers) (1.21.6)\n",
            "Requirement already satisfied: typing-inspect in /usr/local/lib/python3.8/dist-packages (from pyre-extensions==0.0.23->xformers) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from pyre-extensions==0.0.23->xformers) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from triton) (3.9.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from typing-inspect->pyre-extensions==0.0.23->xformers) (1.0.0)\n",
            "Installing collected packages: triton\n",
            "Successfully installed triton-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import requests\n",
        "import torch\n",
        "import gradio as gr\n",
        "import random\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "from diffusers import StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler"
      ],
      "metadata": {
        "id": "XZmWkivMVEYf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading from Diffusers Library\n",
        "model_id = \"timbrooks/instruct-pix2pix\"\n",
        "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16, revision=\"fp16\") #, safety_checker=None)\n",
        "pipe.to(\"cuda\")\n",
        "#pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "pipe.unet.to(memory_format=torch.channels_last)\n",
        "\n",
        "\n",
        "help_text = \"\"\" \n",
        "**Note: Please be advised that a safety checker has been implemented in this public space. \n",
        "    Any attempts to generate inappropriate or NSFW images will result in the display of a black screen \n",
        "    as a precautionary measure to protect all users. We appreciate your cooperation in \n",
        "    maintaining a safe and appropriate environment for all members of our community.**\n",
        "    \n",
        "    New features and bug-fixes: \n",
        "    \n",
        "    1. Chat style interface\n",
        "    2. Now use **'reverse'** as prompt to get back the previous image after an unwanted edit\n",
        "    3. Use **'restart'** as prompt to get back to original image and start over!\n",
        "    4. Now you can load larger image files (~5 mb) as well\n",
        "Some notes from the official [instruct-pix2pix](https://huggingface.co/spaces/timbrooks/instruct-pix2pix) Space by the authors and from the official [Diffusers docs](https://huggingface.co/docs/diffusers/main/en/api/pipelines/stable_diffusion/pix2pix) -\n",
        "If you're not getting what you want, there may be a few reasons:\n",
        "1. Is the image not changing enough? Your guidance_scale may be too low. It should be >1. Higher guidance scale encourages to generate images \n",
        "that are closely linked to the text `prompt`, usually at the expense of lower image quality. This value dictates how similar the output should \n",
        "be to the input. This pipeline requires a value of at least `1`. It's possible your edit requires larger changes from the original image. \n",
        "                \n",
        "2. Alternatively, you can toggle image_guidance_scale. Image guidance scale is to push the generated image towards the inital image. Image guidance \n",
        "                scale is enabled by setting `image_guidance_scale > 1`. Higher image guidance scale encourages to generate images that are closely \n",
        "                linked to the source image `image`, usually at the expense of lower image quality.  \n",
        "3. I have observed that rephrasing the instruction sometimes improves results (e.g., \"turn him into a dog\" vs. \"make him a dog\" vs. \"as a dog\").\n",
        "4. Increasing the number of steps sometimes improves results.\n",
        "5. Do faces look weird? The Stable Diffusion autoencoder has a hard time with faces that are small in the image. Try:\n",
        "    * Cropping the image so the face takes up a larger portion of the frame.\n",
        "\"\"\"\n",
        "\n",
        "css = \"\"\"\n",
        "#col-container {max-width: 580px; margin-left: auto; margin-right: auto;}\n",
        "a {text-decoration-line: underline; font-weight: 600;}\n",
        ".footer {\n",
        "        margin-bottom: 45px;\n",
        "        margin-top: 10px;\n",
        "        text-align: center;\n",
        "        border-bottom: 1px solid #e5e5e5;\n",
        "    }\n",
        "    .footer>p {\n",
        "        font-size: .8rem;\n",
        "        display: inline-block;\n",
        "        padding: 0 10px;\n",
        "        transform: translateY(10px);\n",
        "        background: white;\n",
        "    }\n",
        "    .dark .footer {\n",
        "        border-color: #303030;\n",
        "    }\n",
        "    .dark .footer>p {\n",
        "        background: #0b0f19;\n",
        "    }\n",
        ".animate-spin {\n",
        "    animation: spin 1s linear infinite;\n",
        "}\n",
        "@keyframes spin {\n",
        "    from {\n",
        "        transform: rotate(0deg);\n",
        "    }\n",
        "    to {\n",
        "        transform: rotate(360deg);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "028fba2d819b4d7b809012c806592567",
            "883b152d39884741b02385b2b76f4183",
            "8394c08c71004d48a425076b55099193",
            "b281f21ac150478e92b88481129339d5",
            "e9c384fd1315473e8ccb1f92a4f0092e",
            "c927cc3dafd74518ba09d6a55bd3e9d1",
            "a383d595fd6f41559c97c63cb3f4fb77",
            "70eb0b722b4245cd87fc3d951411c399",
            "b901f37d1aa84c9987cc1d51659948c1",
            "bd12163f7d7645dabe22cc81ff59cb42",
            "724619ed992148449286d06a666ddb3d"
          ]
        },
        "id": "LTJts-t_VCEP",
        "outputId": "746bcd24-6136-4884-82a8-82b2e589818b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "028fba2d819b4d7b809012c806592567"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def previous(image):\n",
        "    return image \n",
        "\n",
        "def upload_image(file):\n",
        "    return Image.open(file)\n",
        "\n",
        "def upload_button_config():\n",
        "    return gr.update(visible=False)\n",
        "\n",
        "def upload_textbox_config(text_in):\n",
        "    return gr.update(visible=True)"
      ],
      "metadata": {
        "id": "NzgZRAyVeCuK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(btn_upload, image_in, in_steps, in_guidance_scale, in_img_guidance_scale, image_hid, img_name, counter_out, image_oneup, prompt, history, progress=gr.Progress(track_tqdm=True)):\n",
        "    progress(0, desc=\"Starting...\")\n",
        "    if prompt != '' and prompt.lower() == 'reverse' : #--to add revert functionality later\n",
        "        history = history or []\n",
        "        temp_img_name = img_name[:-4]+str(int(time.time()))+'.png' \n",
        "        image_oneup.save(temp_img_name)\n",
        "        response = 'Reverted to the last image ' + '<img src=\"/file=' + temp_img_name + '\">'  \n",
        "        history.append((prompt, response))\n",
        "        return history, history, image_oneup, temp_img_name, counter_out\n",
        "    if prompt != '' and prompt.lower() == 'restart' : #--to add revert functionality later\n",
        "        history = history or []\n",
        "        temp_img_name = img_name[:-4]+str(int(time.time()))+'.png' \n",
        "        #Resizing the image\n",
        "        basewidth = 512\n",
        "        wpercent = (basewidth/float(image_in.size[0]))\n",
        "        hsize = int((float(image_in.size[1])*float(wpercent)))\n",
        "        image_in = image_in.resize((basewidth,hsize), Image.Resampling.LANCZOS)\n",
        "        image_in.save(temp_img_name)\n",
        "        response = 'Reverted to the last image ' + '<img src=\"/file=' + temp_img_name + '\">'  \n",
        "        history.append((prompt, response))\n",
        "        return history, history, image_in, temp_img_name, counter_out\n",
        "    #adding supportive sample text\n",
        "    add_text_list = [\"There you go\", \"Enjoy your image!\", \"Nice work! Wonder what you gonna do next!\", \"Way to go!\", \"Does this work for you?\", \"Something like this?\"]        \n",
        "    if counter_out == 0:\n",
        "      t1 = time.time()\n",
        "      print(f\"Time at start = {t1}\")\n",
        "      #convert file object to image\n",
        "      image_in = Image.open(btn_upload)\n",
        "      \n",
        "      #Resizing the image\n",
        "      basewidth = 512\n",
        "      wpercent = (basewidth/float(image_in.size[0]))\n",
        "      hsize = int((float(image_in.size[1])*float(wpercent)))\n",
        "      image_in = image_in.resize((basewidth,hsize), Image.Resampling.LANCZOS)\n",
        "            \n",
        "      # Save the image to the file-like object\n",
        "      seed = random.randint(0, 1000000)\n",
        "      img_name = f\"./edited_image_{seed}.png\"\n",
        "      image_in.save(img_name)\n",
        "      \n",
        "      #add state\n",
        "      history = history or []\n",
        "      response = '<img src=\"/file=' + img_name + '\">'\n",
        "      history.append((prompt, response))\n",
        "      counter_out += 1\n",
        "      \n",
        "      t2 = time.time()\n",
        "      print(f\"Time at end = {t2}\")\n",
        "      time_diff = t2-t1\n",
        "      print(f\"Time taken = {time_diff}\")\n",
        "      return history, history, image_in, img_name, counter_out\n",
        "    \n",
        "    elif counter_out == 1:        \n",
        "      #instruct-pix2pix inference\n",
        "      edited_image = pipe(prompt, image=image_in, num_inference_steps=int(in_steps), guidance_scale=float(in_guidance_scale), image_guidance_scale=float(in_img_guidance_scale)).images[0]\n",
        "      if os.path.exists(img_name):\n",
        "        os.remove(img_name)\n",
        "      temp_img_name = img_name[:-4]+str(int(time.time()))[-4:] +'.png' \n",
        "      with open(temp_img_name, \"wb\") as fp:\n",
        "        # Save the image to the file-like object\n",
        "        edited_image.save(fp)\n",
        "      #Get the name of the saved image\n",
        "      saved_image_name1 = fp.name\n",
        "      history = history or []\n",
        "      response = random.choice(add_text_list) + '<img src=\"/file=' + saved_image_name1 + '\">'   #IMG_NAME\n",
        "      history.append((prompt, response))\n",
        "      counter_out += 1\n",
        "      return history, history, edited_image, temp_img_name, counter_out\n",
        "    \n",
        "    elif counter_out > 1:\n",
        "      edited_image = pipe(prompt, image=image_hid, num_inference_steps=int(in_steps), guidance_scale=float(in_guidance_scale), image_guidance_scale=float(in_img_guidance_scale)).images[0]\n",
        "      if os.path.exists(img_name):\n",
        "        os.remove(img_name)\n",
        "      temp_img_name = img_name[:-4]+str(int(time.time()))[-4:]+'.png' \n",
        "      # Create a file-like object\n",
        "      with open(temp_img_name, \"wb\") as fp:\n",
        "        # Save the image to the file-like object\n",
        "        edited_image.save(fp)\n",
        "      #Get the name of the saved image\n",
        "      saved_image_name2 = fp.name\n",
        "      #edited_image.save(temp_img_name) #, overwrite=True)\n",
        "      history = history or []\n",
        "      response = random.choice(add_text_list) + '<img src=\"/file=' + saved_image_name2 + '\">'  \n",
        "      history.append((prompt, response))\n",
        "      counter_out += 1\n",
        "      return history, history, edited_image, temp_img_name, counter_out"
      ],
      "metadata": {
        "id": "-umQjnF0YOu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Blocks layout\n",
        "with gr.Blocks(css=\"style.css\") as demo:\n",
        "    with gr.Column(elem_id=\"col-container\"):\n",
        "        gr.HTML(\"\"\"<div style=\"text-align: center; max-width: 700px; margin: 0 auto;\">\n",
        "                <div\n",
        "                style=\"\n",
        "                    display: inline-flex;\n",
        "                    align-items: center;\n",
        "                    gap: 0.8rem;\n",
        "                    font-size: 1.75rem;\n",
        "                \"\n",
        "                >\n",
        "                <h1 style=\"font-weight: 900; margin-bottom: 7px; margin-top: 5px;\">\n",
        "                    ChatPix2Pix: Image Editing by Instructions\n",
        "                </h1>\n",
        "                </div>\n",
        "            </div>\"\"\")\n",
        "        with gr.Accordion(\"Advance settings for Training and Inference\", open=False):\n",
        "          image_in = gr.Image(visible=False,type='pil', label=\"Original Image\")\n",
        "          gr.Markdown(\"Advance settings for - Number of Inference steps, Guidanace scale, and Image guidance scale.\")\n",
        "          in_steps = gr.Number(label=\"Enter the number of Inference steps\", value = 20)\n",
        "          in_guidance_scale = gr.Slider(1,10, step=0.5, label=\"Set Guidance scale\", value=7.5)\n",
        "          in_img_guidance_scale = gr.Slider(1,10, step=0.5, label=\"Set Image Guidance scale\", value=1.5)\n",
        "          image_hid = gr.Image(type='pil', visible=False)\n",
        "          image_oneup = gr.Image(type='pil', visible=False)\n",
        "          img_name_temp_out = gr.Textbox(visible=False)\n",
        "          counter_out = gr.Number(visible=False, value=0, precision=0)\n",
        "            \n",
        "        #with gr.Row():\n",
        "        text_in = gr.Textbox(value='', placeholder=\"Type your instructions here and press enter\", elem_id = \"input_prompt\", visible=False, label='Great! Now you can edit your image with Instructions')\n",
        "        btn_upload = gr.UploadButton(\"Upload image to start editing\", file_types=[\"image\"], file_count=\"single\", elem_id=\"upload_button\")\n",
        "        \n",
        "        # chatbot = gr.Chatbot(elem_id = 'chatbot-component', label='Conversational editing for Images')\n",
        "        state_in = gr.State()\n",
        "\n",
        "    \"\"\"\n",
        "    #Using Event Listeners\n",
        "    btn_upload.upload(chat,\n",
        "                      [btn_upload, image_in, in_steps, in_guidance_scale, in_img_guidance_scale, image_hid, img_name_temp_out,counter_out, image_oneup,  text_in, state_in], \n",
        "                      [chatbot, state_in, image_in, img_name_temp_out, counter_out])\n",
        "    btn_upload.upload(fn = upload_textbox_config, inputs=text_in, outputs = text_in)\n",
        "\n",
        "    text_in.submit(chat,[btn_upload, image_in, in_steps, in_guidance_scale, in_img_guidance_scale, image_hid, img_name_temp_out,counter_out, image_oneup,  text_in, state_in], [chatbot, state_in, image_hid, img_name_temp_out, counter_out])\n",
        "    text_in.submit(previous, [image_hid], [image_oneup])\n",
        "    \n",
        "    chatbot.change(fn = upload_button_config, outputs=btn_upload) #, scroll_to_output = True)\n",
        "    text_in.submit(None, [], [], _js = \"() => document.getElementById('#chatbot-component').scrollTop = document.getElementById('#chatbot-component').scrollHeight\")\n",
        "    \"\"\"\n",
        "    #with gr.Accordion(\"Release Notes\", open=False):\n",
        "    gr.Markdown(help_text)"
      ],
      "metadata": {
        "id": "y_QTiHtiWVOI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.queue(concurrency_count=10)\n",
        "demo.launch(debug=True, width=\"80%\", height=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J-xndZT1XWpc",
        "outputId": "06120165-9869-42d2-8b20-2a7752685207"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://e879600c-cbf5-4bb8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e879600c-cbf5-4bb8.gradio.live\" width=\"80%\" height=\"2000\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://e879600c-cbf5-4bb8.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# yolov8 apps"
      ],
      "metadata": {
        "id": "4AsF0WjpeLda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics gradio"
      ],
      "metadata": {
        "id": "_eNB9dI3fSl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "yolo_model = \"yolov8l.pt\"\n",
        "model = YOLO(yolo_model)\n",
        "img_path = \"/content/zidane.jpeg\"\n",
        "infer_size = 640\n",
        "conf = 0.6\n",
        "iou = 0.5\n",
        "results = model(source=img_path, imgsz=infer_size, conf=conf, iou=iou)\n",
        "results = list(results)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3fuxTzMfI7j",
        "outputId": "68c7b748-87f5-4b5f-be83-3802d8a1ba28"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.29 🚀 Python-3.8.10 torch-1.13.1+cu116 CPU\n",
            "YOLOv8l summary (fused): 268 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n",
            "\n",
            "image 1/1 /content/zidane.jpeg: 384x640 2 persons, 1 tie, 1851.9ms\n",
            "Speed: 4.6ms pre-process, 1851.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "cMMiSR0cgqPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xyxy_list = results.boxes.xyxy.cpu().numpy().tolist()\n",
        "conf_list = results.boxes.conf.cpu().numpy().tolist()\n",
        "cls_list = results.boxes.cls.cpu().numpy().tolist()"
      ],
      "metadata": {
        "id": "1rQqBlKWheGE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "import random\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "jWmNOdqEiNad"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_config/model_name_p5_all.yaml\n",
        "# model_names: [\"yolov8n\", \"yolov8s\", \"yolov8m\", \"yolov8l\", \"yolov8x\", \"yolov8n-seg\", \"yolov8s-seg\", \"yolov8m-seg\", \"yolov8l-seg\", \"yolov8x-seg\"]"
      ],
      "metadata": {
        "id": "r-csTthdjcI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cls_name/cls_name_en.yaml\n",
        "\"\"\"\n",
        "model_cls_name: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',\n",
        "    'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
        "    'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle',\n",
        "    'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\n",
        "    'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet',\n",
        "    'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "JOwjOjfNjhvN",
        "outputId": "d972fc6b-07dc-492a-a981-9332c9aae642"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel_cls_name: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\\n    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant',\\n    'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\\n    'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle',\\n    'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli',\\n    'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet',\\n    'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator',\\n    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\\n]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suffix_list = [\".csv\", \".yaml\"]"
      ],
      "metadata": {
        "id": "n_LSSgZSiI16"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yaml文件解析\n",
        "def yaml_parse(file_path):\n",
        "    return yaml.safe_load(open(file_path, encoding=\"utf-8\").read())\n",
        "\n",
        "# yaml csv\n",
        "def yaml_csv(file_path, file_tag):\n",
        "    file_suffix = Path(file_path).suffix\n",
        "    if file_suffix == suffix_list[0]:\n",
        "        file_names = [i[0] for i in list(csv.reader(open(file_path)))]  # csv版\n",
        "    elif file_suffix == suffix_list[1]:\n",
        "        file_names = yaml_parse(file_path).get(file_tag)  # yaml版\n",
        "    else:\n",
        "        print(f\"{file_path}\")\n",
        "        sys.exit()\n",
        "\n",
        "    return file_names"
      ],
      "metadata": {
        "id": "jPjrF-7Rh_5Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cfg = \"/content/model_config/model_name_p5_all.yaml\"\n",
        "cls_name = \"/content/cls_name/cls_name_en.yaml\"\n",
        "\n",
        "model_names = yaml_csv(model_cfg, \"model_names\")  # 模型名称\n",
        "model_cls_name = yaml_csv(cls_name, \"model_cls_name\")  # 类别名称\n",
        "\n",
        "model_cls_name_cp = model_cls_name.copy()  # 类别名称"
      ],
      "metadata": {
        "id": "_tcDIGYmk4RW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_cls_name_cp"
      ],
      "metadata": {
        "id": "NZ08_Baplcpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_color(cls_num, is_light=True):\n",
        "    color_list = []\n",
        "    for i in range(cls_num):\n",
        "        color = (\n",
        "            random.randint(0, 127) + int(is_light) * 128,\n",
        "            random.randint(0, 127) + int(is_light) * 128,\n",
        "            random.randint(0, 127) + int(is_light) * 128,\n",
        "        )\n",
        "        color_list.append(color)\n",
        "\n",
        "    return color_list\n",
        "\n",
        "\n",
        "color_list = random_color(len(model_cls_name_cp), True)"
      ],
      "metadata": {
        "id": "LJvIxbr0hpCP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def draw_image_with_bbox(img, score_list, bbox_list, cls_list, cls_index_list, color_list):\n",
        "  img_pil = ImageDraw.Draw(img)\n",
        "  for score, (xmin, ymin, xmax, ymax), label, cls_index in zip(score_list, bbox_list, cls_list, cls_index_list):\n",
        "        img_pil.rectangle([xmin, ymin, xmax, ymax], fill=None, outline=color_list[cls_index], width=2)  # 边界框\n",
        "        countdown_msg = f\"{id}-{label} {score:.2f}\"\n",
        "\n",
        "        text_w, text_h = 5, 5\n",
        "\n",
        "        img_pil.rectangle(\n",
        "            (xmin, ymin, xmin + text_w, ymin + text_h),\n",
        "            fill=color_list[cls_index],\n",
        "            outline=color_list[cls_index],\n",
        "        )\n",
        "        img_pil.multiline_text(\n",
        "            (xmin, ymin),\n",
        "            countdown_msg,\n",
        "            fill=(0, 0, 0),\n",
        "            align=\"center\",\n",
        "        )\n",
        "\n",
        "        id += 1\n",
        "  return img\n",
        "\n",
        "def polygon_drawing(img_mask, canvas, color_seg):\n",
        "    color_seg = list(color_seg)\n",
        "    color_seg[0], color_seg[2] = color_seg[2], color_seg[0]\n",
        "    color_seg = tuple(color_seg)\n",
        "    pts = np.array(img_mask, dtype=np.int32)\n",
        "\n",
        "    cv2.drawContours(canvas, [pts], -1, color_seg, thickness=-1)\n",
        "\n",
        "\n",
        "def seg_output(img_path, seg_mask_list, color_list, cls_list):\n",
        "    img = cv2.imread(img_path)\n",
        "    img_c = img.copy()\n",
        "\n",
        "    w, h = img.shape[1], img.shape[0]\n",
        "\n",
        "    for seg_mask, cls_index in zip(seg_mask_list, cls_list):\n",
        "        img_mask = []\n",
        "        for i in range(len(seg_mask)):\n",
        "            img_mask.append([seg_mask[i][0] * w, seg_mask[i][1] * h])\n",
        "\n",
        "        polygon_drawing(img_mask, img_c, color_list[int(cls_index)])  \n",
        "\n",
        "    img_mask_merge = cv2.addWeighted(img, 0.3, img_c, 0.7, 0)  \n",
        "\n",
        "    return img_mask_merge\n",
        "\n",
        "def det_image(img_path, model_name, infer_size,  conf, iou):\n",
        "  color_list = random_color(len(model_cls_name_cp), True)\n",
        "\n",
        "  model = YOLO(model_name + \".pt\")\n",
        "  results = model(source=img_path, imgsz=infer_size, conf=conf, iou=iou)\n",
        "  results = list(results)[0]\n",
        "\n",
        "  if (model_name[-3:] == \"seg\"):\n",
        "        masks_list = results.masks.segments\n",
        "        img_mask_merge = seg_output(img_path, masks_list, color_list, cls_list)\n",
        "        img = Image.fromarray(cv2.cvtColor(img_mask_merge, cv2.COLOR_BGRA2RGBA))\n",
        "  else:\n",
        "        img = Image.open(img_path)\n",
        "  \n",
        "  det_img = img\n",
        "  objSize_dict = {}\n",
        "  clsRatio_dict = {}\n",
        "  return det_img, objSize_dict, clsRatio_dict"
      ],
      "metadata": {
        "id": "GiQldKIllvpj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "xVAY6Yi6pTLF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = \"upload\"\n",
        "img_tool = \"editor\"\n",
        "model_name = \"yolov8s\"\n",
        "inference_size=640\n",
        "slider_step=0.1\n",
        "nms_conf = 0.5\n",
        "nms_iou = 0.5\n",
        "# input parameters\n",
        "inputs_img = gr.Image(image_mode=\"RGB\", source=source, tool=img_tool, type=\"filepath\", label=\"base image\")\n",
        "inputs_model01 = gr.Dropdown(choices=model_names, value=model_name, type=\"value\", label=\"model\")\n",
        "inputs_size01 = gr.Slider(384, 1536, step=128, value=inference_size, label=\"infer size\")\n",
        "input_conf01 = gr.Slider(0, 1, step=slider_step, value=nms_conf, label=\"confidence\")\n",
        "inputs_iou01 = gr.Slider(0, 1, step=slider_step, value=nms_iou, label=\"IoU threshold\")\n",
        "\n",
        "# inputs parameters list\n",
        "inputs_img_list = [\n",
        "        inputs_img,  # input image\n",
        "        inputs_model01,  # model\n",
        "        inputs_size01,  # inference_size\n",
        "        input_conf01,  # confidence\n",
        "        inputs_iou01,  # IoU threshold\n",
        "]\n",
        "\n",
        "outputs_img = gr.Image(type=\"pil\", label=\"output\")\n",
        "outputs_objSize = gr.Label(label=\"output_size\")\n",
        "outputs_clsSize = gr.Label(label=\"class_size\")\n",
        "\n",
        "outputs_img_list = [outputs_img, outputs_objSize, outputs_clsSize]\n",
        "\n",
        "title = \"Yolov8 detection\"\n",
        "\n",
        "gyd_img = gr.Interface(\n",
        "        fn=det_image,\n",
        "        inputs=inputs_img_list,\n",
        "        outputs=outputs_img_list,\n",
        "        title=title,\n",
        "        # description=description,\n",
        "        # examples=examples_imgs,\n",
        "        cache_examples=False,\n",
        "        flagging_dir=\"run\", \n",
        "        # allow_flagging=\"manual\",\n",
        "        # flagging_options=[\"good\", \"generally\", \"bad\"],\n",
        ")\n",
        "\n",
        "gyd_img.launch(\n",
        "        inbrowser=True,  \n",
        "        show_tips=True, \n",
        "        debug=True,\n",
        "        # share=is_share,  \n",
        "        # favicon_path=\"./icon/logo.ico\",  \n",
        "        # show_error=True,  \n",
        "        # quiet=True,  \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z7HfjofhoMb7",
        "outputId": "817a2da9-32fa-4bf0-af33-1410a3fffcc9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7862, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tip: Let users specify why they flagged input with the `flagging_options=` kwarg; for example: `gr.Interface(..., flagging_options=['too slow', 'incorrect output', 'other'])`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.29 🚀 Python-3.8.10 torch-1.13.1+cu116 CPU\n",
            "YOLOv8l-seg summary (fused): 295 layers, 45973568 parameters, 0 gradients, 220.5 GFLOPs\n",
            "\n",
            "image 1/1 /tmp/tmpykknfuvj.png: 384x640 1 car, 1 dog, 2209.3ms\n",
            "Speed: 0.9ms pre-process, 2209.3ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/routes.py\", line 344, in run_predict\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 1012, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/gradio/blocks.py\", line 830, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/anyio/to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/anyio/_backends/_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/anyio/_backends/_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"<ipython-input-18-19f8df227425>\", line 63, in det_image\n",
            "    img_mask_merge = seg_output(img_path, masks_list, color_list, cls_list)\n",
            "NameError: name 'cls_list' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4qXvQblqEQL",
        "outputId": "64446302-fac9-4361-a654-1a4fd6400431"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[image, dropdown, slider, slider, slider]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}