{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeTQW2bO2M9n+rX5li98zD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/semantic_segmentation/unet_deeplabv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63hSVoHeN0AM"
      },
      "outputs": [],
      "source": [
        "!wget -q http://imgcom.jsrt.or.jp/imgcom/wp-content/uploads/2018/11/Segmentation01.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/Segmentation01.zip"
      ],
      "metadata": {
        "id": "akvQuuN2OEdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python"
      ],
      "metadata": {
        "id": "39nmfkdtRjXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pytorch_lightning"
      ],
      "metadata": {
        "id": "4sn6jnA9OONU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics==0.7.0"
      ],
      "metadata": {
        "id": "-un3FbMJRaWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import glob\n",
        "import random\n",
        "org_image_root = \"./Segmentation01/train/org/\"\n",
        "label_image_root = \"./Segmentation01/train/label/\"\n",
        "\n",
        "\n",
        "org_images = sorted(glob.glob(org_image_root + \"*.png\"))\n",
        "\n",
        "choice_org_images = random.sample(org_images, 3)\n",
        "choice_label_images = [label_image_root + name.split(\"/\")[-1] for name in choice_org_images]\n",
        "\n",
        "# グラフ領域の作成\n",
        "fig = plt.figure()\n",
        "\n",
        "# 座標軸の作成\n",
        "\n",
        "ax1 = fig.add_subplot(3, 2, 1)\n",
        "ax2 = fig.add_subplot(3, 2, 2)\n",
        "ax3 = fig.add_subplot(3, 2, 3)\n",
        "ax4 = fig.add_subplot(3, 2, 4)\n",
        "ax5 = fig.add_subplot(3, 2, 5)\n",
        "ax6 = fig.add_subplot(3, 2, 6)\n",
        "\n",
        "# データのプロット\n",
        "ax1.imshow(cv2.cvtColor(cv2.imread(choice_org_images[0]), cv2.COLOR_BGR2RGB))\n",
        "ax2.imshow(cv2.cvtColor(cv2.imread(choice_label_images[0]), cv2.COLOR_BGR2RGB))\n",
        "ax3.imshow(cv2.cvtColor(cv2.imread(choice_org_images[1]), cv2.COLOR_BGR2RGB))\n",
        "ax4.imshow(cv2.cvtColor(cv2.imread(choice_label_images[1]), cv2.COLOR_BGR2RGB))\n",
        "ax5.imshow(cv2.cvtColor(cv2.imread(choice_org_images[2]), cv2.COLOR_BGR2RGB))\n",
        "ax6.imshow(cv2.cvtColor(cv2.imread(choice_label_images[2]), cv2.COLOR_BGR2RGB))\n",
        "\n",
        "ax1.axis(\"off\")\n",
        "ax2.axis(\"off\")\n",
        "ax3.axis(\"off\")\n",
        "ax4.axis(\"off\")\n",
        "ax5.axis(\"off\")\n",
        "ax6.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# グラフの表示\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fn5VX5uROJw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import argparse\n",
        "\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "\n",
        "import torchmetrics\n",
        "from torchmetrics.functional import accuracy, iou\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models.segmentation import deeplabv3"
      ],
      "metadata": {
        "id": "vj85QZouQ0rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--image_size\", type=int, default=256)\n",
        "parser.add_argument(\"--batch_size\", type=int, default=4)\n",
        "parser.add_argument(\"--epochs\", type=int, default=100)\n",
        "parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
        "parser.add_argument(\"--patience\", type=int, default=10)\n",
        "args = parser.parse_args(args=[])"
      ],
      "metadata": {
        "id": "U22D0XkGS6gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset and DataLoader\n",
        "## RGB image\n",
        "train_img_list = sorted(glob.glob(\"/content/Segmentation01/train/org/*.png\"))\n",
        "test_img_list = sorted(glob.glob(\"/content/Segmentation01/test/org/*.png\"))\n",
        "\n",
        "## label mask image\n",
        "train_label_list = sorted(glob.glob(\"/content/Segmentation01/train/label/*.png\"))\n",
        "test_label_list = sorted(glob.glob(\"/content/Segmentation01/test/label/*.png\"))\n"
      ],
      "metadata": {
        "id": "iXRRVlnHTqbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(data.Dataset):\n",
        "  def __init__(self, img_path_list, label_path_list, args):\n",
        "    self.image_path_list = img_path_list\n",
        "    self.label_path_list = label_path_list\n",
        "    self.transform = transforms.Compose([transforms.Resize((args.image_size, args.image_size)), transforms.ToTensor()])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_path_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img = Image.open(self.image_path_list[index]).convert(\"RGB\")\n",
        "    img = self.transform(img)\n",
        "\n",
        "    label = Image.open(self.label_path_list[index])\n",
        "    label = self.transform(label)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "45w1ncWfUISZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset and dataloader\n",
        "train_dataset = CustomDataset(train_img_list, train_label_list, args)\n",
        "test_dataset = CustomDataset(test_img_list, test_label_list, args)\n",
        "dataloader = {\n",
        "    \"train\": data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True),\n",
        "    \"val\": data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "}"
      ],
      "metadata": {
        "id": "oH9tufLeVDHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class Net(pl.LightningModule):\n",
        "  def __init__(self, lr:float):\n",
        "    super().__init__()\n",
        "    self.lr = lr\n",
        "    self.model = torchvision.models.segmentation.deeplabv3_resnet101(pretrained=True)\n",
        "    self.model.classifier = deeplabv3.DeepLabHead(2048, 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = self.model(x)\n",
        "    return h\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    x, t = batch\n",
        "    out = self(x)\n",
        "    y = torch.sigmoid(out['out'])\n",
        "    loss = F.binary_cross_entropy_with_logits(out[\"out\"], t)\n",
        "\n",
        "    self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
        "    self.log('train_acc', accuracy(y, t.int()), on_step=True, on_epoch=True, prog_bar=True)\n",
        "    self.log('train_iou', iou(y, t.int()), on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    x, t = batch\n",
        "    out = self(x)\n",
        "    y = torch.sigmoid(out['out'])\n",
        "    loss = F.binary_cross_entropy_with_logits(out[\"out\"], t)\n",
        "\n",
        "    self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
        "    self.log('val_acc', accuracy(y, t.int()), on_step=True, on_epoch=True, prog_bar=True)\n",
        "    self.log('val_iou', iou(y, t.int()), on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters())\n",
        "    return optimizer\n",
        "\n"
      ],
      "metadata": {
        "id": "RVPSUqU3VfMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_MODEL_PATH = \"/content/model/\"\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    SAVE_MODEL_PATH,\n",
        "    filename=\"UNet-\" + \"{epoch:02d}-{val_loss:.2f}\",\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_top_k=1,\n",
        "    save_last=False,\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    patience=args.patience,\n",
        ")"
      ],
      "metadata": {
        "id": "_xjYj5vcW8Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl.seed_everything(0)\n",
        "net = Net(lr=args.lr)\n",
        "trainer = pl.Trainer(max_epochs=args.epochs, callbacks=[model_checkpoint, early_stopping], gpus=1)\n",
        "trainer.fit(net, dataloader[\"train\"], dataloader[\"val\"])"
      ],
      "metadata": {
        "id": "BIRm9RHnX1vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "TMLnlQG5YYts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir lightning_logs/"
      ],
      "metadata": {
        "id": "GDWSqgKVZE06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.callback_metrics"
      ],
      "metadata": {
        "id": "ehhDDY65ZQ4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# deeplabv3などのpretrainedしたモデルをbackboneに用いると50枚程度の多様性を持ったデータセットならマスクイメージを算出可能？\n",
        "# mask imageの領域が大きさとの関連は不明"
      ],
      "metadata": {
        "id": "hGD2yDnuZe_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}