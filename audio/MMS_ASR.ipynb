{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5wilO54+dogekApEMYGhN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/audio/MMS_ASR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "q8mR4Gzm7kEb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcY8PPdV7gb0"
      },
      "outputs": [],
      "source": [
        "!mkdir \"temp_dir\"\n",
        "!git clone https://github.com/pytorch/fairseq\n",
        "\n",
        "# Change current working directory\n",
        "!pwd\n",
        "%cd \"/content/fairseq\"\n",
        "!pip install --editable ./ \n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download model"
      ],
      "metadata": {
        "id": "dHVX07X27unr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MMS-1B:FL102 model - 102 Languages - FLEURS Dataset\n",
        "!wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_fl102.pt'\n",
        "\n",
        "# # MMS-1B:L1107 - 1107 Languages - MMS-lab Dataset\n",
        "# !wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_l1107.pt'\n",
        "\n",
        "# # MMS-1B-all - 1162 Languages - MMS-lab + FLEURS + CV + VP + MLS\n",
        "# !wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_all.pt'"
      ],
      "metadata": {
        "id": "wjKGlaz_7tnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare  demo data"
      ],
      "metadata": {
        "id": "JCKlg2Su70S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P ./audio_samples/ 'https://datasets-server.huggingface.co/assets/google/fleurs/--/en_us/train/0/audio/audio.mp3'\n",
        "!ffmpeg -y -i ./audio_samples/audio.mp3 -ar 16000 ./audio_samples/audio.wav"
      ],
      "metadata": {
        "id": "Y0hJ4sGG7zow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcribe"
      ],
      "metadata": {
        "id": "rHWR08oL779T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
        "os.environ[\"PYTHONPATH\"] = \".\"\n",
        "os.environ[\"PREFIX\"] = \"INFER\"\n",
        "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
        "os.environ[\"USER\"] = \"micro\"\n",
        "\n",
        "!python examples/mms/asr/infer/mms_infer.py --model \"/content/fairseq/models_new/mms1b_fl102.pt\" --lang \"eng\" --audio \"/content/fairseq/audio_samples/audio.wav\""
      ],
      "metadata": {
        "id": "ER_lvM9W7-tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"/content/fairseq/audio_samples/audio.wav\")"
      ],
      "metadata": {
        "id": "cAHc8HwO913q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語"
      ],
      "metadata": {
        "id": "fNFva7D68Glu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://amitaro.conohawing.com/download/voice/003_gomen/taihennmoushiwake_03.wav -P ./audio_samples/\n",
        "!ffmpeg -y -i ./audio_samples/taihennmoushiwake_03.wav -ar 16000 ./audio_samples/audio_jpn.wav"
      ],
      "metadata": {
        "id": "X4-qnFj0_IHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
        "os.environ[\"PYTHONPATH\"] = \".\"\n",
        "os.environ[\"PREFIX\"] = \"INFER\"\n",
        "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
        "os.environ[\"USER\"] = \"micro\"\n",
        "\n",
        "!python examples/mms/asr/infer/mms_infer.py --model \"/content/fairseq/models_new/mms1b_fl102.pt\" --lang \"jpn\" --audio \"/content/fairseq/audio_samples/audio_jpn.wav\""
      ],
      "metadata": {
        "id": "NjVhnPnu8GJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"/content/fairseq/audio_samples/audio.wav\")"
      ],
      "metadata": {
        "id": "O3czei9w_voG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}