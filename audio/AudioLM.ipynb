{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNv745PNo0O/J8DWCWCLfw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/audio/AudioLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "wiOKLkt4AnDk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFL8icH-Aj7F"
      },
      "outputs": [],
      "source": [
        "!pip install diffusers transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library import"
      ],
      "metadata": {
        "id": "med5YN-5A7nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import AudioLDMPipeline\n",
        "\n",
        "from transformers import AutoProcessor, ClapModel"
      ],
      "metadata": {
        "id": "lDmQOAJKA9YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model"
      ],
      "metadata": {
        "id": "bzSkixUsBAAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make Space compatible with CPU duplicates\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    torch_dtype = torch.float16\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    torch_dtype = torch.float32\n",
        "\n",
        "# load the diffusers pipeline\n",
        "repo_id = \"cvssp/audioldm-m-full\"\n",
        "pipe = AudioLDMPipeline.from_pretrained(repo_id, torch_dtype=torch_dtype).to(device)\n",
        "pipe.unet = torch.compile(pipe.unet)\n",
        "\n",
        "# CLAP model (only required for automatic scoring)\n",
        "clap_model = ClapModel.from_pretrained(\"sanchit-gandhi/clap-htsat-unfused-m-full\").to(device)\n",
        "processor = AutoProcessor.from_pretrained(\"sanchit-gandhi/clap-htsat-unfused-m-full\")\n",
        "\n",
        "generator = torch.Generator(device)"
      ],
      "metadata": {
        "id": "cl8Gm9PBBA-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility function"
      ],
      "metadata": {
        "id": "PAqxXj58BDvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_waveforms(text, waveforms):\n",
        "    inputs = processor(text=text, audios=list(waveforms), return_tensors=\"pt\", padding=True)\n",
        "    inputs = {key: inputs[key].to(device) for key in inputs}\n",
        "    with torch.no_grad():\n",
        "        logits_per_text = clap_model(**inputs).logits_per_text  # this is the audio-text similarity score\n",
        "        probs = logits_per_text.softmax(dim=-1)  # we can take the softmax to get the label probabilities\n",
        "        most_probable = torch.argmax(probs)  # and now select the most likely audio waveform\n",
        "    waveform = waveforms[most_probable]\n",
        "    return waveform"
      ],
      "metadata": {
        "id": "St0Rgj9PBFeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input settings"
      ],
      "metadata": {
        "id": "tCRtAvukBH9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"A hammer is hitting a wooden surface\"\n",
        "negative_prompt = \"low quality, average quality\"\n",
        "duration = 5\n",
        "guidance_scale = 2.5\n",
        "n_candidates = 1\n",
        "random_seed = 45"
      ],
      "metadata": {
        "id": "ODsJ81IvBI6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "C7dVXxWpBLMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "waveforms = pipe(\n",
        "        text,\n",
        "        audio_length_in_s=duration,\n",
        "        guidance_scale=guidance_scale,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_waveforms_per_prompt=n_candidates if n_candidates else 1,\n",
        "        generator=generator.manual_seed(int(random_seed)),\n",
        "    )[\"audios\"]\n",
        "if waveforms.shape[0] > 1:\n",
        "  waveform = score_waveforms(text, waveforms)\n",
        "else:\n",
        "  waveform = waveforms[0]"
      ],
      "metadata": {
        "id": "yJcAc0Z_BMlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display and save audio"
      ],
      "metadata": {
        "id": "AOXO8AZZBOkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import scipy\n",
        "# IPython.display.audio(audio)\n",
        "scipy.io.wavfile.write(\"hammer.wav\", rate=16000, data=waveform)\n",
        "IPython.display.Audio(waveform, rate=16000)"
      ],
      "metadata": {
        "id": "1p5gS1hABP7U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}