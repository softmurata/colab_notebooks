{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCPCE8bEURJk7KrFp8nsCs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/audio/elevenlabstts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "KbDA2Gucso8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl-RoXzbsj3w"
      },
      "outputs": [],
      "source": [
        "!pip install elevenlabs -U"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inference"
      ],
      "metadata": {
        "id": "a7LiDNuxs8xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from elevenlabs import generate, play\n",
        "\n",
        "audio = generate(\n",
        "    text=\"Hi! I'm the world's most advanced text-to-speech system, made by elevenlabs.\",\n",
        "    voice=\"Bella\"\n",
        ")\n",
        "\n",
        "play(audio, notebook=True)"
      ],
      "metadata": {
        "id": "BvBj5uSvsxuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multilingal\n",
        "audio = generate(\n",
        "    text=\"¡Hola! Mi nombre es Arnold, encantado de conocerte!\",\n",
        "    voice=\"Arnold\",  # \"Domi\"\n",
        "    model='eleven_multilingual_v1'\n",
        ")\n",
        "\n",
        "play(audio, notebook=True)"
      ],
      "metadata": {
        "id": "vWY6QYtYtRpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from elevenlabs import voices\n",
        "voices = voices()\n",
        "print(voices)"
      ],
      "metadata": {
        "id": "YnuTztwXvbKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語からいろんな声を生成してみよう\n",
        "\n",
        "\n",
        "言語モデルの表\n",
        "\n",
        "https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200\n"
      ],
      "metadata": {
        "id": "Wq_-zlJluCcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "1fPIkTciwPjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "model_name = \"facebook/nllb-200-distilled-600M\"  # facebook/nllb-200-3.3B\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "UwnM4htTwOqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語から英語"
      ],
      "metadata": {
        "id": "YXXJeOPhyL92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"こんにちは、私は他に並ぶもののない最新鋭の言語モデルです。\"\n",
        "inputs = tokenizer(article, return_tensors=\"pt\")\n",
        "\n",
        "translated_tokens = model.generate(\n",
        "    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"eng_Latn\"], max_length=60\n",
        ")\n",
        "ret = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "print(ret)"
      ],
      "metadata": {
        "id": "mhuuGzx1xQVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from elevenlabs import generate, play\n",
        "\n",
        "audio = generate(\n",
        "    text=ret,\n",
        "    voice=\"Bella\"\n",
        ")\n",
        "\n",
        "play(audio, notebook=True)"
      ],
      "metadata": {
        "id": "KQX9ToDIxoAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語からスペイン語\n"
      ],
      "metadata": {
        "id": "kRN0vJoOyPSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang_type = \"epo_Latn\"\n",
        "\n",
        "article = \"こんにちは、私は他に並ぶもののない最新鋭の言語モデルです。\"\n",
        "inputs = tokenizer(article, return_tensors=\"pt\")\n",
        "\n",
        "translated_tokens = model.generate(\n",
        "    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[lang_type], max_length=60\n",
        ")\n",
        "ret = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "print(ret)\n",
        "\n",
        "from elevenlabs import generate, play\n",
        "\n",
        "audio = generate(\n",
        "    text=ret,\n",
        "    voice=\"Bella\",\n",
        "    model='eleven_multilingual_v1'\n",
        ")\n",
        "\n",
        "play(audio, notebook=True)"
      ],
      "metadata": {
        "id": "VjWs_mG-yOwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "日本語からドイツ語"
      ],
      "metadata": {
        "id": "phiFeDWsy0Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang_type = \"deu_Latn\"\n",
        "\n",
        "article = \"こんにちは、私は他に並ぶもののない最新鋭の言語モデルです。\"\n",
        "inputs = tokenizer(article, return_tensors=\"pt\")\n",
        "\n",
        "translated_tokens = model.generate(\n",
        "    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[lang_type], max_length=60\n",
        ")\n",
        "ret = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
        "print(ret)\n",
        "\n",
        "from elevenlabs import generate, play\n",
        "\n",
        "audio = generate(\n",
        "    text=ret,\n",
        "    voice=\"Bella\",\n",
        "    model='eleven_multilingual_v1'\n",
        ")\n",
        "\n",
        "play(audio, notebook=True)"
      ],
      "metadata": {
        "id": "G0IoG96Uy25k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}