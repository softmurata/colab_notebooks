{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO33QQxGcxmQuLcyWt2Y98i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/audio/audiolm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title AudioLm Test\n",
        "#Github(https://github.com/lucidrains/audiolm-pytorch)"
      ],
      "metadata": {
        "id": "ceeuUrRV8-pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOGQpej143xg"
      },
      "outputs": [],
      "source": [
        "# LibriSpeech Dataset(https://www.openslr.org/12/)\n",
        "!wget https://www.openslr.org/resources/12/test-clean.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://qiita.com/supersaiakujin/items/c6b54e9add21d375161f\n",
        "!tar -zxvf test-clean.tar.gz"
      ],
      "metadata": {
        "id": "q1mpfX3A5CsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiolm-pytorch"
      ],
      "metadata": {
        "id": "MQQJIG4h5UnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train SoundStream\n",
        "data_folder = \"/content/LibriSpeech/test-clean\"  #@param"
      ],
      "metadata": {
        "id": "9p8botnT9ImU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from audiolm_pytorch import SoundStream, SoundStreamTrainer\n",
        "soundstream = SoundStream(\n",
        "    codebook_size=1024,\n",
        "    rq_num_quantizers=8,\n",
        ")\n",
        "\n",
        "trainer = SoundStreamTrainer(\n",
        "    soundstream,\n",
        "    folder=\"/content/LibriSpeech/test-clean\",\n",
        "    batch_size=4,\n",
        "    grad_accum_every=8,\n",
        "    data_max_length=320 * 32,\n",
        "    num_train_steps=1500\n",
        ").cuda()\n",
        "\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "DPwbiTUY5bnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train 3 transformers\n",
        "# SemanticTransformer, CoarseTransformer, FineTransformer(SoundStream weights are needed for training them)"
      ],
      "metadata": {
        "id": "f0H_e5ti6nsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download hubert weights\n",
        "# hubert checkpoints can be downloaded at\n",
        "# https://github.com/facebookresearch/fairseq/tree/main/examples/hubert\n",
        "!mkdir hubert\n",
        "!wget -O ./hubert/hubert_base_ls960.pt https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960.pt\n",
        "!wget -O ./hubert/hubert_base_ls960_L9_km500.bin https://dl.fbaipublicfiles.com/hubert/hubert_base_ls960_L9_km500.bin"
      ],
      "metadata": {
        "id": "4z1xFWnJ7bo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from audiolm_pytorch import HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer"
      ],
      "metadata": {
        "id": "Bm1ZT5rY9S2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title params\n",
        "hubert_weight_path = '/content/hubert/hubert_base_ls960.pt' #@param\n",
        "kmeans_weight_path = './hubert/hubert_base_ls960_L9_km500.bin' #@param\n",
        "soundstream_weight_path = '/content/results/soundstream.0.pt'  #@param\n",
        "data_folder = \"/content/LibriSpeech/test-clean\"  #@param"
      ],
      "metadata": {
        "id": "CeLWFxrY_SNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wav2vec = HubertWithKmeans(\n",
        "    checkpoint_path = hubert_weight_path,\n",
        "    kmeans_path = kmeans_weight_path,\n",
        ")\n",
        "\n",
        "semantic_transformer = SemanticTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    dim = 1024,\n",
        "    depth = 6\n",
        ").cuda()\n",
        "\n",
        "\n",
        "trainer = SemanticTransformerTrainer(\n",
        "    transformer = semantic_transformer,\n",
        "    wav2vec = wav2vec,\n",
        "    folder = data_folder,\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 1\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "7Vsmd87D9PGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wav2vec = HubertWithKmeans(\n",
        "    checkpoint_path = hubert_weight_path,\n",
        "    kmeans_path = kmeans_weight_path,\n",
        ")\n",
        "\n",
        "soundstream = SoundStream(\n",
        "    codebook_size = 1024,\n",
        "    rq_num_quantizers = 8,\n",
        ")\n",
        "\n",
        "# soundstream.load('/path/to/trained/soundstream.pt')\n",
        "soundstream.load(soundstream_weight_path)\n",
        "\n",
        "coarse_transformer = CoarseTransformer(\n",
        "    num_semantic_tokens = wav2vec.codebook_size,\n",
        "    codebook_size = 1024,\n",
        "    num_coarse_quantizers = 3,\n",
        "    dim = 512,\n",
        "    depth = 6\n",
        ")\n",
        "\n",
        "trainer = CoarseTransformerTrainer(\n",
        "    transformer = coarse_transformer,\n",
        "    soundstream = soundstream,\n",
        "    wav2vec = wav2vec,\n",
        "    folder = data_folder,\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 1500\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "NIVVIBXp-Y22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soundstream = SoundStream(\n",
        "    codebook_size = 1024,\n",
        "    rq_num_quantizers = 8,\n",
        ")\n",
        "\n",
        "soundstream.load(soundstream_weight_path)\n",
        "\n",
        "fine_transformer = FineTransformer(\n",
        "    num_coarse_quantizers = 3,\n",
        "    num_fine_quantizers = 5,\n",
        "    codebook_size = 1024,\n",
        "    dim = 512,\n",
        "    depth = 6\n",
        ")\n",
        "\n",
        "trainer = FineTransformerTrainer(\n",
        "    transformer = fine_transformer,\n",
        "    soundstream = soundstream,\n",
        "    folder = data_folder,\n",
        "    batch_size = 1,\n",
        "    data_max_length = 320 * 32,\n",
        "    num_train_steps = 1500\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "D8IpMUBJ-sQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title inference\n",
        "from audiolm_pytorch import AudioLM\n",
        "\n",
        "audiolm = AudioLM(\n",
        "    wav2vec = wav2vec,\n",
        "    soundstream = soundstream,\n",
        "    semantic_transformer = semantic_transformer,\n",
        "    coarse_transformer = coarse_transformer,\n",
        "    fine_transformer = fine_transformer\n",
        ")\n",
        "\n",
        "generated_wav = audiolm(batch_size = 1)\n",
        "\n",
        "# or with priming\n",
        "\n",
        "generated_wav_with_prime = audiolm(prime_wave = torch.randn(1, 320 * 8))\n",
        "\n",
        "# or with text condition, if given\n",
        "\n",
        "generated_wav_with_text_condition = audiolm(text = ['chirping of birds and the distant echos of bells'])"
      ],
      "metadata": {
        "id": "jr5GeY_K_GY5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}