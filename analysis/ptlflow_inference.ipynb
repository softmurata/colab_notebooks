{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/analysis/ptlflow_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxVAAk7-cFlo"
      },
      "source": [
        "# PTLFlow inference demo\n",
        "\n",
        "This notebook shows a basic example on how to use PTLFlow ([https://github.com/hmorimitsu/ptlflow](https://github.com/hmorimitsu/ptlflow)) to estimate the optical flow between a pair of images.\n",
        "\n",
        "In the first example, we will use the `infer.py` script provided by PTLFlow to do the estimation. The second example will show how to write a simple code to estimate the optical flow without the script.\n",
        "\n",
        "More details can be found in the official documentation at [https://ptlflow.readthedocs.io](https://ptlflow.readthedocs.io)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B9AggWCXKbD"
      },
      "source": [
        "# First install the PTLFlow package with pip\n",
        "!pip install ptlflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compatible occurs, Please uninstall or install suitable version with pytorch and torchvision\n",
        "!pip uninstall torchtext torchaudio"
      ],
      "metadata": {
        "id": "AwsOTriNznQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txMLf8PhXPrL"
      },
      "source": [
        "# Import ptlflow and some dependencies for the example\n",
        "import ptlflow\n",
        "\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6ABF5_5enh5"
      },
      "source": [
        "# Download two images to serve as inputs to the optical flow model\n",
        "# The images below are from the MPI-Sintel dataset: http://sintel.is.tue.mpg.de/\n",
        "!wget https://github.com/hmorimitsu/sift-flow-gpu/raw/master/mpi_sintel_images/frame_0001.png\n",
        "!wget https://github.com/hmorimitsu/sift-flow-gpu/raw/master/mpi_sintel_images/frame_0002.png\n",
        "cv2_imshow(cv.imread('frame_0001.png'))\n",
        "cv2_imshow(cv.imread('frame_0002.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOI1_-ZIebeY"
      },
      "source": [
        "## Example 1 - with infer.py\n",
        "\n",
        "We first need to download the `infer.py` script. This can be done with the code below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7tMkMWkXgnB",
        "outputId": "c2f3ba6e-6b52-4022-b1fd-6a63f8890024"
      },
      "source": [
        "ptlflow.download_scripts()\n",
        "\n",
        "# If you want to download the script directly from a terminal, you can run:\n",
        "# python -c \"import ptlflow; ptlflow.download_scripts()\"\n",
        "\n",
        "# Go to the folder where the scripts were downloaded to\n",
        "%cd ptlflow_scripts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ptlflow_scripts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2nKueT6f5nk"
      },
      "source": [
        "Now that we have the script, we can use it to estimate the optical flow between our two images.\n",
        "\n",
        "The code below does this using the small version of the RAFT model (see [https://github.com/princeton-vl/RAFT](https://github.com/princeton-vl/RAFT)). We are also going to initialize the RAFT network with the weights obtained after training on the FlyingThings3D dataset.\n",
        "\n",
        "The `--write_outputs` argument is used to save the outputs of the network to the disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEZqUbJjX7IY"
      },
      "source": [
        "!python infer.py craft --pretrained_ckpt things --input_path ../frame_0001.png ../frame_0002.png --write_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aO4QKunYHiP"
      },
      "source": [
        "# Let's visualize the predicted flow\n",
        "flow_pred = cv.imread('outputs/inference/flows_viz/frame_0001.png')\n",
        "cv2_imshow(flow_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otTHlQ6ihqxN"
      },
      "source": [
        "## Example 2 - without infer.py\n",
        "\n",
        "This example will show how to write a short code to do the same thing as in the previous example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4hUPJlkY_oI"
      },
      "source": [
        "# Additional dependencies for this example\n",
        "from ptlflow.utils.io_adapter import IOAdapter\n",
        "from ptlflow.utils import flow_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqHdPD7xZteM"
      },
      "source": [
        "# Load the two images\n",
        "img1 = cv.imread('../frame_0001.png')\n",
        "img2 = cv.imread('../frame_0002.png')\n",
        "\n",
        "# Get an initialized model from PTLFlow\n",
        "model = ptlflow.get_model('raft_small', 'things')\n",
        "model.eval()\n",
        "\n",
        "# IOAdapter is a helper to transform the two images into the input format accepted by PTLFlow models\n",
        "io_adapter = IOAdapter(model, img1.shape[:2])\n",
        "inputs = io_adapter.prepare_inputs([img1, img2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlNUCGv_aWyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09f318b-b5c2-4daa-aab3-d808c155967d"
      },
      "source": [
        "# Forward the inputs to obtain the model predictions\n",
        "predictions = model(inputs)\n",
        "\n",
        "# Some padding may have been added during prepare_inputs. The line below ensures that the padding is removed\n",
        "# to make the predictions have the same size as the original images.\n",
        "predictions = io_adapter.unpad_and_unscale(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqaMFZJdahPX"
      },
      "source": [
        "# Visualize the predicted flow\n",
        "flow = predictions['flows'][0, 0]  # Remove batch and sequence dimensions\n",
        "flow = flow.permute(1, 2, 0)  # change from CHW to HWC shape\n",
        "flow = flow.detach().numpy()\n",
        "flow_viz = flow_utils.flow_to_rgb(flow)  # Represent the flow as RGB colors\n",
        "flow_viz = cv.cvtColor(flow_viz, cv.COLOR_BGR2RGB)  # OpenCV uses BGR format\n",
        "cv2_imshow(flow_viz)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrDbdobTn10R"
      },
      "source": [
        "#@title Training\n",
        "# !python -c \"import ptlflow; print(ptlflow.get_trainable_model_names())\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}