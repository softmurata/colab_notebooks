{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+7KVOoTEXk9ny3ioLR+Iu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/vision3d/live3d_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLjPcJQQouCx"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/transpchan/Live3D-v2.git\n",
        "%cd Live3D-v2\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download weights\n",
        "!mkdir weights\n",
        "#!curl -O -J -L  https://github.com/transpchan/Live3D-v2/releases/download/checkpoints-2.1/checkpoints.zip\n",
        "!curl -O -J -L  https://github.com/transpchan/Live3D-v2/releases/download/checkpoints-2.2/checkpoints.zip\n",
        "!unzip checkpoints.zip -d ./weights/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0fQUc0Epo-l",
        "outputId": "9300e42a-9f53-4770-df54-a4e3db669438"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  423M  100  423M    0     0  39.0M      0  0:00:10  0:00:10 --:--:-- 31.5M\n",
            "curl: Saved to filename 'checkpoints.zip'\n",
            "Archive:  checkpoints.zip\n",
            "  inflating: ./weights/cinnnet.pth   \n",
            "  inflating: ./weights/rgbadecodernet.pth  \n",
            "  inflating: ./weights/udpadecodernet.pth  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "character = 'double_ponytail' #@param ['double_ponytail', 'short_hair', 'self_defined']"
      ],
      "metadata": {
        "id": "pSl0U8L8pstL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm *.zip.*\n",
        "!rm -r character_sheet/\n",
        "!rm -r poses/\n",
        "!mkdir character_sheet/\n",
        "if character == 'short_hair':\n",
        "  !curl -O -J -L  https://github.com/transpchan/Live3D-v2/releases/download/samples/short_hair_images.zip\n",
        "  !unzip -j  short_hair_images.zip -x '__MACOSX/*'  -d character_sheet/character/ \n",
        "elif character == 'double_ponytail':\n",
        "  !curl -O -J -L  https://github.com/transpchan/Live3D-v2/releases/download/samples/double_ponytail_images.zip\n",
        "  !unzip -j  double_ponytail_images.zip -x '__MACOSX/*' -d character_sheet/character/\n",
        "else:\n",
        "  print(\"Please upload your character sheets to /content/CoNR/character_sheet/ \")\n",
        "if character == 'short_hair':\n",
        "  !curl -O -J -L  https://github.com/transpchan/Live3D-v2/releases/download/samples/short_hair.zip\n",
        "  !unzip -j  short_hair.zip -d poses/\n",
        "elif character == 'double_ponytail':\n",
        "  !curl -O -J -L  https://github.com/transpchan/Live3D-v2/releases/download/samples/double_ponytail.zip\n",
        "  !unzip -j double_ponytail.zip -d poses/ \n",
        "else:\n",
        "  print(\"Please upload your UDP sequences or poses images to /content/CoNR/poses/ .\")"
      ],
      "metadata": {
        "id": "b8WXPyEip5NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Show all character sheets\n",
        "from IPython.display import Image,display\n",
        "from pathlib import Path\n",
        "path ='./character_sheet/'\n",
        "imgs = []\n",
        "for file in Path(path).rglob('*.[PpWw][NnEe][GgBb]*'):\n",
        "          imgs.append(Image(filename=str(file), width=200))\n",
        "          \n",
        "print(\"Num of character sheets:\", len(imgs))\n",
        "display(*imgs)"
      ],
      "metadata": {
        "id": "9oZnlTwap-pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Run UDP Detector\n",
        "#@markdown This additional demo will show the results by running the udp detector on the character sheet. If you want to run it on the pose sequence, you need to change the code in train.py\n",
        "!pip install open3d\n",
        "!mkdir results\n",
        "!python3 train.py --mode=test \\\n",
        "--test_input_poses_images=./character_sheet/character/ \\\n",
        "--test_input_person_images=./character_sheet/ \\\n",
        "--test_output_dir=./results/ \\\n",
        "--test_checkpoint_dir=./weights/  \\\n",
        "--test_output_udp=True \\\n",
        "--test_output_video=False \\\n",
        "--test_pose_use_parser_udp=True"
      ],
      "metadata": {
        "id": "0KCkibtYqEiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (Optional) Visualzie UDP detection results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import numpy as np\n",
        "    import open3d as o3d\n",
        "\n",
        "    npz = np.load('./results/udp_0.npz', allow_pickle=True)\n",
        "    print(\"img count:\", npz[\"udp\"].shape[0])\n",
        "    a = np.moveaxis(npz[\"udp\"][:, :, :, :], [2, 3], [0, 1]).reshape(-1, 4)\n",
        "    img = np.moveaxis(npz[\"img\"][:, :, :, :], [2, 3], [0, 1]).reshape(-1, 3)\n",
        "\n",
        "    occulusion = (a[:, 3] > 0.90)\n",
        "\n",
        "    xyz = a[occulusion, 0:3]\n",
        "    rgb = img[occulusion, 0:3]\n",
        "    print(\"points:\", xyz.shape[0])\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(xyz*[0.7, 0.25, 1])\n",
        "\n",
        "    pcd.colors = o3d.utility.Vector3dVector(rgb)\n",
        "    pcd.estimate_normals()\n",
        "    pcd.orient_normals_consistent_tangent_plane(1)\n",
        "\n",
        "    pcd2 = o3d.geometry.PointCloud()\n",
        "    pcd2.points = o3d.utility.Vector3dVector([\n",
        "        [0, 0, 0],\n",
        "        [1, 0, 0],\n",
        "        [0, 1, 0],\n",
        "        [1, 1, 0],\n",
        "        [0, 0, 1],\n",
        "        [1, 0, 1],\n",
        "        [0, 1, 1],\n",
        "        [1, 1, 1],\n",
        "    ])\n",
        "\n",
        "    pcd2.paint_uniform_color([0.5, 0.5, 0.5])\n",
        "    o3d.visualization.draw_plotly([pcd, pcd2])\n",
        "    if False:\n",
        "        print(\"Displaying pointcloud ...\")\n",
        "        o3d.visualization.draw([pcd])\n",
        "    o3d.io.write_point_cloud(\"./pointcloud.ply\", pcd)"
      ],
      "metadata": {
        "id": "RHFHgJR7qv7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Video Generation\n",
        "#@markdown For sample data, this process may take about 40 minutes. You can stop earlier to get an shorter result (by clicking stop on the left).\n",
        "!mkdir results\n",
        "!python3 train.py --mode=test \\\n",
        "--test_input_poses_images=./poses/ \\\n",
        "--test_input_person_images=./character_sheet/ \\\n",
        "--test_output_dir=./results/ \\\n",
        "--test_checkpoint_dir=./weights/ "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VElmH2Xq_oy",
        "outputId": "a72990be-b93a-46a7-e90b-764db5ea6638"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘results’: File exists\n",
            "world_size: 0\n",
            "batch_size: 1\n",
            "local_rank:  0\n",
            "character sheet: ['character_sheet/character/未命名作品 1.png', 'character_sheet/character/未命名作品 2.png', 'character_sheet/character/未命名作品 3.png', 'character_sheet/character/未命名作品 4.png']\n",
            "---\n",
            "test images:  1459\n",
            "---\n",
            "Infer: 100%|█████████████████| 1459/1459 [1:48:37<00:00,  4.47s/it, data_time=4.3, train_time=0.542]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert video format for display\n",
        "#@markdown `output.mp4` is the output with black background.  `output_adobe_premiere.mov` is the output with transparent background.\n",
        "!ffmpeg -r 30 -y -i ./results/%d.png  -c:v qtrle output_adobe_premiere.mov \n",
        "!ffmpeg -r 30 -y -i ./results/%d.png  -c:v libx264 -strict -2 -pix_fmt yuv420p   output.mp4 "
      ],
      "metadata": {
        "id": "fQ0ZvfFXEBj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Play the generated video!\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        " \n",
        "def show_video(video_path, video_width = 600):\n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"\n",
        "<video width=\"100%\" height=\"100%\" controls>\n",
        "      <source src=\"{video_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")\n",
        "show_video('output.mp4')"
      ],
      "metadata": {
        "id": "nk56e4sSEIF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tips\n",
        "# motion diffusion modelと組み合わせて動画が作れるかどうかを試す。realtime chatみたいなのができないかを試す。"
      ],
      "metadata": {
        "id": "wSPNKYwuErz7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}