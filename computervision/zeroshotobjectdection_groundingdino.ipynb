{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHMqod8J2SrYsbbeQAlCFe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/computervision/zeroshotobjectdection_groundingdino.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "wQmpzjARjdPB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqxA--FGjNer"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "HOME = \"/content\"\n",
        "%cd {HOME}\n",
        "!git clone https://github.com/IDEA-Research/GroundingDINO.git\n",
        "%cd {HOME}/GroundingDINO\n",
        "!pip install -q -e .\n",
        "!pip install -q roboflow\n",
        "\n",
        "CONFIG_PATH = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
        "print(CONFIG_PATH, \"; exist:\", os.path.isfile(CONFIG_PATH))\n",
        "\n",
        "%cd {HOME}\n",
        "!mkdir {HOME}/weights\n",
        "%cd {HOME}/weights\n",
        "\n",
        "!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
        "WEIGHTS_NAME = \"groundingdino_swint_ogc.pth\"\n",
        "WEIGHTS_PATH = os.path.join(HOME, \"weights\", WEIGHTS_NAME)\n",
        "print(WEIGHTS_PATH, \"; exist:\", os.path.isfile(WEIGHTS_PATH))\n",
        "\n",
        "%cd {HOME}\n",
        "!mkdir {HOME}/data\n",
        "%cd {HOME}/data\n",
        "\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-4.jpeg\n",
        "\n",
        "%cd {HOME}/GroundingDINO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "pV3nRVrgj2u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import supervision as sv\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import pycocotools.mask as mask_util\n",
        "from groundingdino.util.inference import load_model, load_image, predict, annotate"
      ],
      "metadata": {
        "id": "CTnD_gkdj38y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load grounding dino model"
      ],
      "metadata": {
        "id": "vQbdtP-4j8lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HOME = \"/content\"\n",
        "CONFIG_PATH = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
        "WEIGHTS_NAME = \"groundingdino_swint_ogc.pth\"\n",
        "WEIGHTS_PATH = os.path.join(HOME, \"weights\", WEIGHTS_NAME)\n",
        "detection_model = load_model(CONFIG_PATH, WEIGHTS_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIILihwJj98D",
        "outputId": "0841d646-0ec8-4876-c8b8-47995665be31"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final text_encoder_type: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download test image"
      ],
      "metadata": {
        "id": "91GIOEnElHng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg -O /content/test.jpeg"
      ],
      "metadata": {
        "id": "GQUmeyPglJLE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "VI60_h6jkL0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title dog\n",
        "IMAGE_PATH = \"/content/test.jpeg\"\n",
        "\n",
        "TEXT_PROMPT = \"dog\"  # rectangle, region, shape region, segment, fragment\n",
        "BOX_TRESHOLD = 0.3  # 0.05~0.1 -> 部品点数とか図面の密度に応じている.\n",
        "TEXT_TRESHOLD = 0.3  # 0.05~0.1\n",
        "\n",
        "image_source, image = load_image(IMAGE_PATH)\n",
        "\n",
        "boxes, logits, phrases = predict(\n",
        "    model=detection_model, \n",
        "    image=image, \n",
        "    caption=TEXT_PROMPT, \n",
        "    box_threshold=BOX_TRESHOLD, \n",
        "    text_threshold=TEXT_TRESHOLD\n",
        ")\n",
        "\n",
        "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "\n",
        "%matplotlib inline  \n",
        "sv.plot_image(annotated_frame, (16, 16))"
      ],
      "metadata": {
        "id": "_wNhprxhkMxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title building\n",
        "IMAGE_PATH = \"/content/test.jpeg\"\n",
        "\n",
        "TEXT_PROMPT = \"building\"  # rectangle, region, shape region, segment, fragment\n",
        "BOX_TRESHOLD = 0.3  # 0.05~0.1 -> 部品点数とか図面の密度に応じている.\n",
        "TEXT_TRESHOLD = 0.3  # 0.05~0.1\n",
        "\n",
        "image_source, image = load_image(IMAGE_PATH)\n",
        "\n",
        "boxes, logits, phrases = predict(\n",
        "    model=detection_model, \n",
        "    image=image, \n",
        "    caption=TEXT_PROMPT, \n",
        "    box_threshold=BOX_TRESHOLD, \n",
        "    text_threshold=TEXT_TRESHOLD\n",
        ")\n",
        "\n",
        "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "\n",
        "%matplotlib inline  \n",
        "sv.plot_image(annotated_frame, (16, 16))"
      ],
      "metadata": {
        "id": "YGrQAtG5l-ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pipeline function"
      ],
      "metadata": {
        "id": "S1x3QgBcoaH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_pipeline(image_path, text_prompt, box_threshold=0.3, text_threshold=0.3):\n",
        "  image_source, image = load_image(image_path)\n",
        "\n",
        "  boxes, logits, phrases = predict(\n",
        "      model=detection_model, \n",
        "      image=image, \n",
        "      caption=text_prompt, \n",
        "      box_threshold=box_threshold, \n",
        "      text_threshold=text_threshold\n",
        "  )\n",
        "\n",
        "  annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
        "\n",
        "  %matplotlib inline  \n",
        "  sv.plot_image(annotated_frame, (16, 16))\n"
      ],
      "metadata": {
        "id": "P8w7yva8ocJ-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advanced Inference"
      ],
      "metadata": {
        "id": "3Iw9pWR5mbcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://prtimes.jp/i/1355/5420/resize/d1355-5420-149832-0.jpg -O /content/soccer.jpg"
      ],
      "metadata": {
        "id": "WVunfkYSmdCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_pipeline(\"/content/soccer.jpg\", \"ball\", 0.2, 0.2)"
      ],
      "metadata": {
        "id": "vmNF36R0no0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_pipeline(\"/content/soccer.jpg\", \"player,ball\", 0.2, 0.2)"
      ],
      "metadata": {
        "id": "yncrmHrIqAH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# soccer 2\n",
        "!wget https://prtimes.jp/i/31288/7/resize/d31288-7-332931-0.png -O /content/soccer.png"
      ],
      "metadata": {
        "id": "SWRypsmQqiuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_pipeline(\"/content/soccer.png\", \"goal\", 0.2, 0.2)"
      ],
      "metadata": {
        "id": "5Q5m1v88qn80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title intersection\n",
        "!wget https://camera-map.com/wp-content/uploads/ann-shibuya.jpg -O /content/intersection.jpg"
      ],
      "metadata": {
        "id": "XAu8BjrKr1nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_pipeline(\"/content/intersection.jpg\", \"car\", 0.17, 0.17)"
      ],
      "metadata": {
        "id": "wXOv4EAmsFES"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}