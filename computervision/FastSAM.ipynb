{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNyNrbPVtCnN0FMM9uKgV9B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/colab_notebooks/blob/main/computervision/FastSAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "CyQgx11VVjlq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAYkmxNiIZlz"
      },
      "outputs": [],
      "source": [
        "!git clone https://huggingface.co/spaces/An-619/FastSAM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FastSAM\n",
        "!pip install -r requirements.txt\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "GdUQPJdsIj3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start WebUI"
      ],
      "metadata": {
        "id": "eOYpcJd9VkuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FastSAM\n",
        "!python app.py"
      ],
      "metadata": {
        "id": "AwjXXwvvIsIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stable diffusion with background"
      ],
      "metadata": {
        "id": "T1yVC74PJiht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/SysCV/sam-hq.git"
      ],
      "metadata": {
        "id": "RSQ8lnPySt0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA is available:\", torch.cuda.is_available())\n",
        "\n",
        "os.chdir('sam-hq')\n",
        "!export PYTHONPATH=$(pwd)\n",
        "from segment_anything import sam_model_registry, SamPredictor"
      ],
      "metadata": {
        "id": "KE_d9FiyLMeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pretrained_checkpoint\n",
        "!wget https://huggingface.co/lkeab/hq-sam/resolve/main/sam_hq_vit_l.pth\n",
        "!mv sam_hq_vit_l.pth pretrained_checkpoint"
      ],
      "metadata": {
        "id": "OqV_UMM4LZrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils function\n",
        "def show_mask(mask, ax, random_color=False):\n",
        "    if random_color:\n",
        "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
        "    else:\n",
        "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
        "    h, w = mask.shape[-2:]\n",
        "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
        "    ax.imshow(mask_image)\n",
        "\n",
        "def show_points(coords, labels, ax, marker_size=375):\n",
        "    pos_points = coords[labels==1]\n",
        "    neg_points = coords[labels==0]\n",
        "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
        "\n",
        "def show_box(box, ax):\n",
        "    x0, y0 = box[0], box[1]\n",
        "    w, h = box[2] - box[0], box[3] - box[1]\n",
        "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))\n",
        "\n",
        "\n",
        "def show_res(masks, scores, input_point, input_label, input_box, image):\n",
        "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
        "        plt.figure(figsize=(10,10))\n",
        "        plt.imshow(image)\n",
        "        show_mask(mask, plt.gca())\n",
        "        if input_box is not None:\n",
        "            box = input_box[i]\n",
        "            show_box(box, plt.gca())\n",
        "        if (input_point is not None) and (input_label is not None):\n",
        "            show_points(input_point, input_label, plt.gca())\n",
        "\n",
        "        print(f\"Score: {score:.3f}\")\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def show_res_multi(masks, scores, input_point, input_label, input_box, image):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image)\n",
        "    for mask in masks:\n",
        "        show_mask(mask, plt.gca(), random_color=True)\n",
        "    for box in input_box:\n",
        "        show_box(box, plt.gca())\n",
        "    for score in scores:\n",
        "        print(f\"Score: {score:.3f}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "bgWM_qCNMYR2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sam_checkpoint = \"pretrained_checkpoint/sam_hq_vit_l.pth\"\n",
        "model_type = \"vit_l\"\n",
        "device = \"cuda\"\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "predictor = SamPredictor(sam)"
      ],
      "metadata": {
        "id": "VD42G_hcMdQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/anya.jpeg')\n",
        "print(image.shape)"
      ],
      "metadata": {
        "id": "mMIz1jS-Mn84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "input_box = np.array([[5,5,180,250]])\n",
        "input_point, input_label = None, None\n",
        "predictor.set_image(image)\n",
        "masks, scores, logits = predictor.predict(\n",
        "    point_coords=input_point,\n",
        "    point_labels=input_label,\n",
        "    box = input_box,\n",
        "    multimask_output=False,\n",
        "    hq_token_only= False,\n",
        ")\n",
        "show_res(masks,scores,input_point, input_label, input_box, image)"
      ],
      "metadata": {
        "id": "La93iWL-MN6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/anya.jpeg')\n",
        "input_point = np.array([[95,40],[165, 55], [30, 55], [50,230],[140, 230]])\n",
        "input_label = np.ones(input_point.shape[0])\n",
        "input_box = None\n",
        "predictor.set_image(image)\n",
        "masks, scores, logits = predictor.predict(\n",
        "    point_coords=input_point,\n",
        "    point_labels=input_label,\n",
        "    box = input_box,\n",
        "    multimask_output=False,\n",
        "    hq_token_only= True,\n",
        ")\n",
        "show_res(masks,scores,input_point, input_label, input_box, image)"
      ],
      "metadata": {
        "id": "jDgEt-ItTsVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "for mask in masks:\n",
        "  h, w = mask.shape[-2:]\n",
        "  display(Image.fromarray(~mask))\n",
        "  Image.fromarray(~mask).save(\"/content/anya_mask.jpg\")"
      ],
      "metadata": {
        "id": "KFro78RSNJlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Background CivitAI"
      ],
      "metadata": {
        "id": "y63EOe1dMOkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7536\n",
        "!wget https://civitai.com/api/download/models/7536 -O /content/background.safetensors"
      ],
      "metadata": {
        "id": "aRiSKNIuJmYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers accelerate bitsandbytes transformers"
      ],
      "metadata": {
        "id": "cUtDdpm9PXXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "import torch"
      ],
      "metadata": {
        "id": "RCwd4K1OQGh9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"stablediffusionapi/anything-v5\"\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(model_name, torch_dtype=torch.float16)\n",
        "pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "_sLe3LC7Qch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "init_image = Image.open(\"/content/anya.jpeg\").resize((512, 512))\n",
        "mask_image = Image.open(\"/content/anya_mask.jpg\").resize((512, 512))\n",
        "bw, bh = Image.open(\"/content/anya.jpeg\").size"
      ],
      "metadata": {
        "id": "-r2Jes8ySDQ0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"wedding party\"\n",
        "image = pipe(prompt=prompt, image=init_image, mask_image=mask_image, num_inference_steps=30).images[0]\n",
        "display(image.resize((bw, bh)))"
      ],
      "metadata": {
        "id": "hxTRYR-zQ4B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9Tz9Li-QO_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}